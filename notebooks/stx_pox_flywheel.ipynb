{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f42d40b",
      "metadata": {},
      "source": [
        "# Stacks PoX Flywheel: Fees \u2192 Miner Rewards \u2192 BTC Bids \u2192 PoX Yields\n",
        "\n",
        "This notebook reconstructs the Stacks Proof-of-Transfer (PoX) flywheel by joining fees, miner rewards, BTC bids, and stacker yields at the burn-block (tenure) level. It relies on the Signal21 public API for market and fee data and the Hiro Stacks API for burn chain metadata.\n",
        "\n",
        "**Objectives**\n",
        "- Pull full-history STX/BTC prices, transaction fees, PoX rewards, and anchor metadata.\n",
        "- Construct a tenure-level panel with derived reward value and \\(\r",
        "ho = \f",
        "rac{\text{BTC commit}}{\text{reward value}}\\).\n",
        "- Quantify fee uplift scenarios (+10/25/50/100/200%) to estimate incremental BTC commits and PoX APY shifts.\n",
        "\n",
        "**References**\n",
        "- [Signal21 API docs](https://app.signal21.io/docs/api.html)\n",
        "- [Signal21 API access](https://signal21.github.io/docs/extras/api-access.html)\n",
        "- [Hiro Stacks API reference](https://www.hiro.so/stacks-api)\n",
        "- [Stacks fee mechanics](https://docs.stacks.co/concepts/network-fundamentals/network)\n",
        "- [Stacks mempool fee endpoint](https://www.quicknode.com/docs/stacks/v2/extended-v2-mempool-fees)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d58b2615",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running outside Colab; ensure you execute from the repo root.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    repo_path = Path('/content/stx-labs')\n",
        "    if repo_path.exists():\n",
        "        subprocess.run(['git', '-C', str(repo_path), 'reset', '--hard', 'origin/main'], check=True)\n",
        "        subprocess.run(['git', '-C', str(repo_path), 'fetch', '--all'], check=True)\n",
        "        subprocess.run(['git', '-C', str(repo_path), 'checkout', 'main'], check=True)\n",
        "        subprocess.run(['git', '-C', str(repo_path), 'pull', '--ff-only'], check=True)\n",
        "    else:\n",
        "        subprocess.run(['git', 'clone', 'https://github.com/seconds-0/stx-labs.git', str(repo_path)], check=True)\n",
        "    os.chdir(repo_path)\n",
        "    subprocess.run(['pip', 'install', '--quiet', '-r', 'requirements.txt'], check=True)\n",
        "    print('Colab environment ready: repo synced and dependencies installed.')\n",
        "else:\n",
        "    print('Running outside Colab; ensure you execute from the repo root.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "187fa302",
      "metadata": {},
      "source": [
        "## 1. Configuration & Environment Checks\n",
        "\n",
        "Edit the cell below to configure date windows, retry policy, and manual overrides. Set `HIRO_API_KEY` in your environment (or in the notebook UI) before running the data acquisition cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6c823bc8",
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from datetime import UTC, datetime, timedelta\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def _find_project_root(start: Path) -> Path:\n",
        "    for candidate in (start, *start.parents):\n",
        "        if (candidate / 'src').is_dir():\n",
        "            return candidate\n",
        "    raise RuntimeError('Unable to locate project root containing a src/ directory.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = _find_project_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "from src import config as cfg  # noqa: E402\n",
        "\n",
        "# -------- User Parameters -------- #\n",
        "WINDOW_DAYS = (30, 90, 180)\n",
        "HISTORY_DAYS = cfg.default_date_horizon_days()\n",
        "CUSTOM_START_DATE = None  # set to datetime(YYYY, M, D, tzinfo=UTC) to override history days\n",
        "END_DATE = datetime.now(UTC)\n",
        "ANALYSIS_START = CUSTOM_START_DATE or (END_DATE - timedelta(days=HISTORY_DAYS))\n",
        "FORCE_REFRESH = False  # force-refresh all caches when True\n",
        "PRICE_SYMBOLS = (\"STX-USD\", \"BTC-USD\")\n",
        "\n",
        "# Scenario assumptions\n",
        "COINBASE_STX = 1_000.0\n",
        "FEE_PER_TX_STX = 0.08\n",
        "RHO_RANGE = (0.3, 0.5, 0.7)\n",
        "UPLIFT_POINTS = (0.10, 0.25, 0.50, 1.00, 2.00)\n",
        "REWARD_BLOCKS_PER_CYCLE = 2100\n",
        "\n",
        "RAW_PATH = cfg.RAW_DATA_DIR\n",
        "CACHE_PATH = cfg.CACHE_DIR\n",
        "OUT_PATH = cfg.OUT_DIR\n",
        "for path in (RAW_PATH, CACHE_PATH, OUT_PATH):\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "HIRO_API_KEY = os.getenv(cfg.HIRO_API_KEY_ENV)\n",
        "if not HIRO_API_KEY:\n",
        "    print('\u26a0\ufe0f Set HIRO_API_KEY before running Hiro API calls.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c489d1a",
      "metadata": {},
      "source": [
        "## 2. Imports & Helper Setup\n",
        "\n",
        "The helper modules live in `src/` and encapsulate Signal21/Hiro API access, caching, and scenario math."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c3f6b4f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from src import hiro, panel_builder, prices, scenarios\n",
        "from src.fees import fetch_fee_per_tx_summary, fetch_fees_by_tenure\n",
        "from src.signal21 import probe_schema\n",
        "\n",
        "pd.options.display.float_format = \"{:.6f}\".format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a184fdf",
      "metadata": {},
      "source": [
        "## 3. Parameter Summary & Cache Status\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d004f239",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analysis window: 2024-10-22 22:13 \u2192 2025-10-22 22:13 UTC\n",
            "History days: 365 (custom start: None)\n",
            "Force refresh: False\n",
            "STX-USD cache: empty\n",
            "BTC-USD cache: empty\n",
            "Fees cache: missing (data/cache/signal21/fees_by_tenure_all.parquet)\n",
            "Rewards cache: missing (data/cache/hiro/rewards_all.parquet)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Analysis window: {ANALYSIS_START:%Y-%m-%d %H:%M} \u2192 {END_DATE:%Y-%m-%d %H:%M} UTC\")\n",
        "print(f\"History days: {HISTORY_DAYS} (custom start: {CUSTOM_START_DATE})\")\n",
        "print(f\"Force refresh: {FORCE_REFRESH}\")\n",
        "\n",
        "from src.prices import cached_price_series\n",
        "from src.cache_utils import read_parquet\n",
        "\n",
        "for symbol in PRICE_SYMBOLS:\n",
        "    cache_df = cached_price_series(symbol)\n",
        "    if cache_df.empty:\n",
        "        print(f\"{symbol} cache: empty\")\n",
        "    else:\n",
        "        print(\n",
        "            f\"{symbol} cache: {len(cache_df):,} rows \"\n",
        "            f\"({cache_df['ts'].min():%Y-%m-%d} \u2192 {cache_df['ts'].max():%Y-%m-%d})\"\n",
        "        )\n",
        "\n",
        "fees_cache = cfg.CACHE_DIR / 'signal21' / 'fees_by_tenure_all.parquet'\n",
        "rewards_cache = cfg.CACHE_DIR / 'hiro' / 'rewards_all.parquet'\n",
        "for label, path in [('Fees cache', fees_cache), ('Rewards cache', rewards_cache)]:\n",
        "    exists = path.exists()\n",
        "    msg = \"exists\" if exists else \"missing\"\n",
        "    print(f\"{label}: {msg} ({path})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bb11e90",
      "metadata": {},
      "source": [
        "## 4. Schema Discovery (Signal21)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "08e8ad45",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to inspect schema when needed\n",
        "# tx_sample = probe_schema(\"core.txs\")\n",
        "# block_sample = probe_schema(\"core.blocks\")\n",
        "# display(tx_sample.head())\n",
        "# display(block_sample.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b07c5a7",
      "metadata": {},
      "source": [
        "## 4. Data Acquisition\n",
        "\n",
        "This section ingests prices, fees, PoX rewards, and anchor metadata. Each request uses robust retry logic and caches raw payloads under `data/raw/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "105a3348",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alexanderhuth/Code/stx-labs/src/prices.py:114: RuntimeWarning: CoinGecko failed for STX-USD: 404 Client Error: Not Found for url: https://api.coingecko.com/api/v3/coins/stacks/market_chart/range?vs_currency=usd&from=1729635215&to=1761171215. Falling back to Signal21.\n",
            "  warnings.warn(\n",
            "/Users/alexanderhuth/Code/stx-labs/src/signal21.py:60: RuntimeWarning: Signal21 price API repeatedly failed for STX-USD between 2025-10-17 and 2025-10-22: Status 500 for https://api-test.signal21.io/v1/price. Skipping chunk.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "cache_before = {symbol: len(prices.cached_price_series(symbol)) for symbol in PRICE_SYMBOLS}\n",
        "prices_df = prices.load_price_panel(ANALYSIS_START, END_DATE, force_refresh=FORCE_REFRESH)\n",
        "cache_after = {symbol: len(prices.cached_price_series(symbol)) for symbol in PRICE_SYMBOLS}\n",
        "\n",
        "for symbol in PRICE_SYMBOLS:\n",
        "    before = cache_before[symbol]\n",
        "    after = cache_after[symbol]\n",
        "    delta = after - before\n",
        "    print(f\"{symbol}: {after:,} cached rows (\u0394 {delta:+,})\")\n",
        "print(\n",
        "    f\"Price panel rows: {len(prices_df):,} spanning \"\n",
        "    f\"{prices_df['ts'].min()} \u2192 {prices_df['ts'].max()}\"\n",
        ")\n",
        "prices_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c6700a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "fees_df = fetch_fees_by_tenure(force_refresh=FORCE_REFRESH)\n",
        "if fees_df.empty:\n",
        "    print(\"\u26a0\ufe0f No fee data returned.\")\n",
        "else:\n",
        "    print(\n",
        "        f\"Fees rows: {len(fees_df):,} burn blocks \"\n",
        "        f\"({fees_df['burn_block_height'].min()} \u2192 {fees_df['burn_block_height'].max()})\"\n",
        "    )\n",
        "fees_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd83b3a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "if fees_df.empty:\n",
        "    rewards_df = pd.DataFrame()\n",
        "else:\n",
        "    min_height = int(fees_df['burn_block_height'].min())\n",
        "    max_height = int(fees_df['burn_block_height'].max())\n",
        "    rewards_df = hiro.aggregate_rewards_by_burn_block(\n",
        "        start_height=min_height,\n",
        "        end_height=max_height,\n",
        "        force_refresh=FORCE_REFRESH,\n",
        "    )\n",
        "    print(\n",
        "        f\"Rewards rows: {len(rewards_df):,} burn blocks \"\n",
        "        f\"({rewards_df['burn_block_height'].min()} \u2192 {rewards_df['burn_block_height'].max()})\"\n",
        "    )\n",
        "rewards_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9b4e5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "if fees_df.empty:\n",
        "    anchor_df = pd.DataFrame()\n",
        "else:\n",
        "    anchor_df = hiro.collect_anchor_metadata(fees_df['burn_block_height'].astype(int), force_refresh=FORCE_REFRESH)\n",
        "    print(f\"Collected anchor metadata for {anchor_df.shape[0]} burn blocks\")\n",
        "anchor_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69e34aa9",
      "metadata": {},
      "outputs": [],
      "source": [
        "cycles_df = hiro.list_pox_cycles(force_refresh=FORCE_REFRESH)\n",
        "print(f\"Retrieved {cycles_df.shape[0]} PoX cycles\")\n",
        "cycles_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d41f3b0",
      "metadata": {},
      "source": [
        "## 5. Tenure Panel Construction\n",
        "\n",
        "Join all datasets on `burn_block_height`, align prices to anchor timestamps, and derive reward value and \\(\r",
        "ho\\)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1349c29d",
      "metadata": {},
      "outputs": [],
      "source": [
        "if fees_df.empty or anchor_df.empty:\n",
        "    panel_df = pd.DataFrame()\n",
        "else:\n",
        "    panel_cfg = panel_builder.PanelConfig(coinbase_stx=COINBASE_STX)\n",
        "    panel_df = panel_builder.build_tenure_panel(\n",
        "        fees=fees_df,\n",
        "        rewards=rewards_df,\n",
        "        anchors=anchor_df,\n",
        "        prices=prices_df,\n",
        "        config=panel_cfg,\n",
        "    )\n",
        "    panel_df = panel_builder.merge_cycle_metadata(panel_df, cycles_df)\n",
        "    print(f\"Panel contains {panel_df.shape[0]} tenures\")\n",
        "panel_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "095aba55",
      "metadata": {},
      "source": [
        "## 6. Validation Checks\n",
        "\n",
        "Ensure we have consistent tenure coverage, expected coinbase value, and reasonable \\(\r",
        "ho\\) ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c1c59b",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not panel_df.empty:\n",
        "    missing_fees = panel_df['fees_stx_sum'].isna().sum()\n",
        "    coinbase_anomalies = panel_df['coinbase_flag'].sum()\n",
        "    rho_div_zero = panel_df['rho_flag_div0'].sum()\n",
        "    print(\"Missing fee entries:\", missing_fees)\n",
        "    print(\"Coinbase anomalies:\", coinbase_anomalies)\n",
        "    print(\"Zero reward value entries:\", rho_div_zero)\n",
        "\n",
        "    expected_burns = panel_df['burn_block_height'].iloc[-1] - panel_df['burn_block_height'].iloc[0] + 1\n",
        "    missing_burns = expected_burns - len(panel_df['burn_block_height'].unique())\n",
        "    print(\"Missing burn heights:\", missing_burns)\n",
        "\n",
        "    sample = panel_df.sample(min(20, len(panel_df)))\n",
        "    sample[['burn_block_height', 'fees_stx_sum', 'reward_amount_sats_sum', 'rho']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99f4a183",
      "metadata": {},
      "source": [
        "## 7. Fee Analytics Per Window\n",
        "\n",
        "Compute empirical fee-per-transaction statistics across rolling windows to benchmark against the 0.08 STX/tx baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8dee625",
      "metadata": {},
      "outputs": [],
      "source": [
        "fee_stats = {}\n",
        "for window in WINDOW_DAYS:\n",
        "    stats_df = fetch_fee_per_tx_summary(window, force_refresh=FORCE_REFRESH)\n",
        "    fee_stats[window] = stats_df\n",
        "    print(f\"Window {window}d -> observations: {stats_df.shape[0]}\")\n",
        "fee_summary_df = pd.concat({f\"{w}d\": df for w, df in fee_stats.items()}, names=[\"window\", \"row\"])\n",
        "fee_summary_df.groupby(level=\"window\").agg({\"avg_fee_stx\": \"mean\", \"median_fee_stx\": \"mean\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "495cc947",
      "metadata": {},
      "source": [
        "## 8. Scenario Engine\n",
        "\n",
        "Estimate the incremental transactions, BTC commits, and PoX APY shifts for fee uplifts. `stacked_supply_stx` defaults to a rolling estimate when available, otherwise falls back to 1.35B STX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd92e7c",
      "metadata": {},
      "outputs": [],
      "source": [
        "if panel_df.empty:\n",
        "    scenario_df = pd.DataFrame()\n",
        "else:\n",
        "    recent_panel = panel_df.tail(max(3_000, len(panel_df)))\n",
        "    mean_fee_stx = recent_panel['fees_stx_sum'].mean()\n",
        "    mean_stx_btc = recent_panel['stx_btc'].mean()\n",
        "    stacked_supply_estimate = (\n",
        "        recent_panel['reward_stx_total'].rolling(REWARD_BLOCKS_PER_CYCLE).sum().dropna().iloc[-1]\n",
        "        if len(recent_panel) >= REWARD_BLOCKS_PER_CYCLE\n",
        "        else 1_350_000_000.0\n",
        "    )\n",
        "    scenario_cfg = scenarios.ScenarioConfig(\n",
        "        fee_per_tx_stx=FEE_PER_TX_STX,\n",
        "        rho_candidates=RHO_RANGE,\n",
        "        coinbase_stx=COINBASE_STX,\n",
        "        reward_cycles_blocks=REWARD_BLOCKS_PER_CYCLE,\n",
        "        stacked_supply_stx=stacked_supply_estimate,\n",
        "    )\n",
        "    scenario_df = scenarios.build_scenarios(\n",
        "        uplift_rates=UPLIFT_POINTS,\n",
        "        mean_fee_stx=mean_fee_stx,\n",
        "        mean_stx_btc=mean_stx_btc,\n",
        "        config=scenario_cfg,\n",
        "    )\n",
        "    scenario_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9355c70",
      "metadata": {},
      "source": [
        "## 9. Visualizations\n",
        "\n",
        "Produce canonical charts: time series of fees and BTC commits, \\(\r",
        "ho\\) distribution, and scatter of reward value vs. BTC commits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c52c65",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not panel_df.empty:\n",
        "    time_fig = px.line(\n",
        "        panel_df.tail(5_000),\n",
        "        x=\"burn_block_time_iso\",\n",
        "        y=[\"fees_stx_sum\", \"reward_amount_sats_sum\"],\n",
        "        labels={\"value\": \"Amount\", \"burn_block_time_iso\": \"Burn Block Time\"},\n",
        "        title=\"Tenure Fees vs. BTC Commit (Rolling)\",\n",
        "    )\n",
        "    time_fig.show()\n",
        "\n",
        "    rho_fig = px.histogram(panel_df, x=\"rho\", nbins=50, title=\"Distribution of Rho\")\n",
        "    rho_fig.show()\n",
        "\n",
        "    scatter_fig = px.scatter(\n",
        "        panel_df,\n",
        "        x=\"reward_value_sats\",\n",
        "        y=\"reward_amount_sats_sum\",\n",
        "        trendline=\"ols\",\n",
        "        title=\"BTC Commit vs. Reward Value\",\n",
        "        labels={\"reward_value_sats\": \"Reward Value (sats)\", \"reward_amount_sats_sum\": \"BTC Commit (sats)\"},\n",
        "    )\n",
        "    scatter_fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de0e6118",
      "metadata": {},
      "source": [
        "## 10. Artifact Export\n",
        "\n",
        "Persist key datasets to `./data/` and `./out/` for downstream usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dba6ecb",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not panel_df.empty:\n",
        "    panel_path = OUT_PATH / \"tenure_panel.parquet\"\n",
        "    fees_path = OUT_PATH / \"fees_by_tenure.parquet\"\n",
        "    rewards_path = OUT_PATH / \"pox_rewards.parquet\"\n",
        "    price_path = OUT_PATH / \"prices.parquet\"\n",
        "    scenario_path = OUT_PATH / \"scenario_table.csv\"\n",
        "\n",
        "    panel_df.to_parquet(panel_path, index=False)\n",
        "    fees_df.to_parquet(fees_path, index=False)\n",
        "    rewards_df.to_parquet(rewards_path, index=False)\n",
        "    prices_df.to_parquet(price_path, index=False)\n",
        "    scenario_df.to_csv(scenario_path, index=False)\n",
        "\n",
        "    print(\"Saved panel ->\", panel_path)\n",
        "    print(\"Saved fees ->\", fees_path)\n",
        "    print(\"Saved rewards ->\", rewards_path)\n",
        "    print(\"Saved prices ->\", price_path)\n",
        "    print(\"Saved scenario table ->\", scenario_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "884740ae",
      "metadata": {},
      "source": [
        "## 11. Next Steps\n",
        "\n",
        "- Extend to cycle-level aggregates (sum commits, rewards, rho by PoX cycle).\n",
        "- Add pool attribution analytics by incorporating stacker addresses.\n",
        "- Compare realized fees with Hiro mempool fee estimates for additional validation.\n",
        "- Integrate notebook with Deepnote (recommended) for easy sharing; sync with this repo for reproducibility."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}