{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f42d40b",
      "metadata": {},
      "source": [
        "# Stacks PoX Flywheel: Fees \u2192 Miner Rewards \u2192 BTC Bids \u2192 PoX Yields\n",
        "\n",
        "This notebook reconstructs the Stacks Proof-of-Transfer (PoX) flywheel by joining fees, miner rewards, BTC bids, and stacker yields at the burn-block (tenure) level. It relies on the Signal21 public API for market and fee data and the Hiro Stacks API for burn chain metadata.\n",
        "\n",
        "**Objectives**\n",
        "- Pull full-history STX/BTC prices, transaction fees, PoX rewards, and anchor metadata.\n",
        "- Construct a tenure-level panel with derived reward value and \\(\r",
        "ho = \f",
        "rac{\text{BTC commit}}{\text{reward value}}\\).\n",
        "- Quantify fee uplift scenarios (+10/25/50/100/200%) to estimate incremental BTC commits and PoX APY shifts.\n",
        "\n",
        "**References**\n",
        "- [Signal21 API docs](https://app.signal21.io/docs/api.html)\n",
        "- [Signal21 API access](https://signal21.github.io/docs/extras/api-access.html)\n",
        "- [Hiro Stacks API reference](https://www.hiro.so/stacks-api)\n",
        "- [Stacks fee mechanics](https://docs.stacks.co/concepts/network-fundamentals/network)\n",
        "- [Stacks mempool fee endpoint](https://www.quicknode.com/docs/stacks/v2/extended-v2-mempool-fees)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d58b2615",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running outside Colab; ensure you execute from the repo root.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    repo_path = Path('/content/stx-labs')\n",
        "    if repo_path.exists():\n",
        "        subprocess.run(['git', '-C', str(repo_path), 'reset', '--hard', 'origin/main'], check=True)\n",
        "        subprocess.run(['git', '-C', str(repo_path), 'fetch', '--all'], check=True)\n",
        "        subprocess.run(['git', '-C', str(repo_path), 'checkout', 'main'], check=True)\n",
        "        subprocess.run(['git', '-C', str(repo_path), 'pull', '--ff-only'], check=True)\n",
        "    else:\n",
        "        subprocess.run(['git', 'clone', 'https://github.com/seconds-0/stx-labs.git', str(repo_path)], check=True)\n",
        "    os.chdir(repo_path)\n",
        "    subprocess.run(['pip', 'install', '--quiet', '-r', 'requirements.txt'], check=True)\n",
        "    print('Colab environment ready: repo synced and dependencies installed.')\n",
        "else:\n",
        "    print('Running outside Colab; ensure you execute from the repo root.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "187fa302",
      "metadata": {},
      "source": [
        "## 1. Configuration & Environment Checks\n",
        "\n",
        "Edit the cell below to configure date windows, retry policy, and manual overrides. Set `HIRO_API_KEY` in your environment (or in the notebook UI) before running the data acquisition cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6c823bc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from datetime import UTC, datetime, timedelta\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def _find_project_root(start: Path) -> Path:\n",
        "    for candidate in (start, *start.parents):\n",
        "        if (candidate / 'src').is_dir():\n",
        "            return candidate\n",
        "    raise RuntimeError(\"Unable to locate project root containing a src/ directory.\")\n",
        "\n",
        "PROJECT_ROOT = _find_project_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "from src import config as cfg\n",
        "\n",
        "# src.config automatically loads .env (HIRO_API_KEY, etc.)\n",
        "\n",
        "# -------- User Parameters -------- #\n",
        "WINDOW_DAYS = (30, 90, 180)\n",
        "USE_FULL_HISTORY = True  # pull as far back as available when True\n",
        "START_DATE = datetime.now(UTC) - timedelta(days=5 * 365)\n",
        "END_DATE = datetime.now(UTC)\n",
        "FORCE_REFRESH = False  # set True to bypass local cache\n",
        "\n",
        "# Scenario assumptions\n",
        "COINBASE_STX = 1_000.0\n",
        "FEE_PER_TX_STX = 0.08\n",
        "RHO_RANGE = (0.3, 0.5, 0.7)\n",
        "UPLIFT_POINTS = (0.10, 0.25, 0.50, 1.00, 2.00)\n",
        "REWARD_BLOCKS_PER_CYCLE = 2100\n",
        "\n",
        "RAW_PATH = cfg.RAW_DATA_DIR\n",
        "OUT_PATH = cfg.OUT_DIR\n",
        "RAW_PATH.mkdir(parents=True, exist_ok=True)\n",
        "OUT_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "HIRO_API_KEY = os.getenv(cfg.HIRO_API_KEY_ENV)\n",
        "if not HIRO_API_KEY:\n",
        "    print(\"\u26a0\ufe0f Set HIRO_API_KEY before running Hiro API calls.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c489d1a",
      "metadata": {},
      "source": [
        "## 2. Imports & Helper Setup\n",
        "\n",
        "The helper modules live in `src/` and encapsulate Signal21/Hiro API access, caching, and scenario math."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c3f6b4f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from src import hiro, panel_builder, prices, scenarios\n",
        "from src.fees import fetch_fee_per_tx_summary, fetch_fees_by_tenure\n",
        "from src.signal21 import probe_schema\n",
        "\n",
        "pd.options.display.float_format = \"{:.6f}\".format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a184fdf",
      "metadata": {},
      "source": [
        "## 3. Schema Discovery (Signal21)\n",
        "\n",
        "Run these exploratory queries intermittently to confirm dataset layouts. Results are cached locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "08e8ad45",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to inspect schema when needed\n",
        "# tx_sample = probe_schema(\"core.txs\")\n",
        "# block_sample = probe_schema(\"core.blocks\")\n",
        "# display(tx_sample.head())\n",
        "# display(block_sample.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b07c5a7",
      "metadata": {},
      "source": [
        "## 4. Data Acquisition\n",
        "\n",
        "This section ingests prices, fees, PoX rewards, and anchor metadata. Each request uses robust retry logic and caches raw payloads under `data/raw/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "105a3348",
      "metadata": {},
      "outputs": [
        {
          "ename": "TransientHTTPError",
          "evalue": "Status 500 for https://api-test.signal21.io/v1/price",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTransientHTTPError\u001b[39m                        Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m price_start = START_DATE \u001b[38;5;28;01mif\u001b[39;00m USE_FULL_HISTORY \u001b[38;5;28;01melse\u001b[39;00m datetime.utcnow() - timedelta(days=\u001b[38;5;28mmax\u001b[39m(WINDOW_DAYS))\n\u001b[32m      2\u001b[39m price_end = END_DATE\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m prices_df = \u001b[43mprices\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_price_panel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprice_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_refresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFORCE_REFRESH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prices_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m hourly price records spanning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprices_df[\u001b[33m'\u001b[39m\u001b[33mts\u001b[39m\u001b[33m'\u001b[39m].min()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprices_df[\u001b[33m'\u001b[39m\u001b[33mts\u001b[39m\u001b[33m'\u001b[39m].max()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m prices_df.head()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/stx-labs/src/prices.py:20\u001b[39m, in \u001b[36mload_price_panel\u001b[39m\u001b[34m(start, end, frequency, force_refresh)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_price_panel\u001b[39m(\n\u001b[32m     13\u001b[39m     start: datetime,\n\u001b[32m     14\u001b[39m     end: datetime,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     force_refresh: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     18\u001b[39m ) -> pd.DataFrame:\n\u001b[32m     19\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return merged STX-USD, BTC-USD, and STX/BTC hourly data.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     stx = \u001b[43mfetch_price_series\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSTX-USD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_refresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_refresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     btc = fetch_price_series(\u001b[33m\"\u001b[39m\u001b[33mBTC-USD\u001b[39m\u001b[33m\"\u001b[39m, start, end, frequency=frequency, force_refresh=force_refresh)\n\u001b[32m     23\u001b[39m     df = (\n\u001b[32m     24\u001b[39m         stx.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mpx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mstx_usd\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m     25\u001b[39m         .merge(btc.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mpx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mbtc_usd\u001b[39m\u001b[33m\"\u001b[39m}), on=\u001b[33m\"\u001b[39m\u001b[33mts\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mouter\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m         .sort_values(\u001b[33m\"\u001b[39m\u001b[33mts\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/stx-labs/src/signal21.py:39\u001b[39m, in \u001b[36mfetch_price_series\u001b[39m\u001b[34m(symbol, start, end, frequency, force_refresh)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk_start, chunk_end \u001b[38;5;129;01min\u001b[39;00m _iter_date_chunks(start, end):\n\u001b[32m     34\u001b[39m     params = {\n\u001b[32m     35\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msymbol\u001b[39m\u001b[33m\"\u001b[39m: symbol,\n\u001b[32m     36\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom\u001b[39m\u001b[33m\"\u001b[39m: chunk_start.strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m     37\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mto\u001b[39m\u001b[33m\"\u001b[39m: chunk_end.strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m     38\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     payload = \u001b[43mcached_json_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mRequestOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msignal21_price\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m            \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_signal21_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPRICE_ENDPOINT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_refresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_refresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     chunk_df = pd.DataFrame(payload)\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunk_df.empty:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/stx-labs/src/http_utils.py:130\u001b[39m, in \u001b[36mcached_json_request\u001b[39m\u001b[34m(opts)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;129m@retry\u001b[39m(\n\u001b[32m    120\u001b[39m     retry=retry_if_exception(_retry_condition),\n\u001b[32m    121\u001b[39m     wait=wait_exponential_jitter(\n\u001b[32m   (...)\u001b[39m\u001b[32m    126\u001b[39m )\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute\u001b[39m() -> Any:\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _request_once(opts)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m payload = \u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m _store_cache(cache_path, payload)\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m payload\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/stx-labs/.venv/lib/python3.13/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/stx-labs/.venv/lib/python3.13/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/stx-labs/.venv/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/stx-labs/.venv/lib/python3.13/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/stx-labs/.venv/lib/python3.13/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/stx-labs/.venv/lib/python3.13/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/stx-labs/src/http_utils.py:128\u001b[39m, in \u001b[36mcached_json_request.<locals>._execute\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;129m@retry\u001b[39m(\n\u001b[32m    120\u001b[39m     retry=retry_if_exception(_retry_condition),\n\u001b[32m    121\u001b[39m     wait=wait_exponential_jitter(\n\u001b[32m   (...)\u001b[39m\u001b[32m    126\u001b[39m )\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute\u001b[39m() -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_request_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/stx-labs/src/http_utils.py:95\u001b[39m, in \u001b[36m_request_once\u001b[39m\u001b[34m(opts)\u001b[39m\n\u001b[32m     86\u001b[39m response = opts.session.request(\n\u001b[32m     87\u001b[39m     opts.method,\n\u001b[32m     88\u001b[39m     opts.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m     92\u001b[39m     timeout=\u001b[32m30\u001b[39m,\n\u001b[32m     93\u001b[39m )\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _should_retry(response.status_code):\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TransientHTTPError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStatus \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopts.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     96\u001b[39m response.raise_for_status()\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[31mTransientHTTPError\u001b[39m: Status 500 for https://api-test.signal21.io/v1/price"
          ]
        }
      ],
      "source": [
        "price_start = START_DATE if USE_FULL_HISTORY else datetime.now(UTC) - timedelta(days=max(WINDOW_DAYS))\n",
        "price_end = END_DATE\n",
        "prices_df = prices.load_price_panel(price_start, price_end, force_refresh=FORCE_REFRESH)\n",
        "print(f\"Loaded {len(prices_df)} hourly price records spanning {prices_df['ts'].min()} to {prices_df['ts'].max()}\")\n",
        "prices_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c6700a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "fees_df = fetch_fees_by_tenure(force_refresh=FORCE_REFRESH)\n",
        "print(f\"Fetched fee aggregates for {fees_df.shape[0]} burn blocks\")\n",
        "fees_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd83b3a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "if fees_df.empty:\n",
        "    rewards_df = pd.DataFrame()\n",
        "else:\n",
        "    min_height = int(fees_df['burn_block_height'].min())\n",
        "    max_height = int(fees_df['burn_block_height'].max())\n",
        "    rewards_df = hiro.aggregate_rewards_by_burn_block(start_height=min_height, end_height=max_height, force_refresh=FORCE_REFRESH)\n",
        "    print(f\"Aggregated PoX rewards for {rewards_df.shape[0]} burn blocks\")\n",
        "rewards_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9b4e5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "if fees_df.empty:\n",
        "    anchor_df = pd.DataFrame()\n",
        "else:\n",
        "    anchor_df = hiro.collect_anchor_metadata(fees_df['burn_block_height'].astype(int), force_refresh=FORCE_REFRESH)\n",
        "    print(f\"Collected anchor metadata for {anchor_df.shape[0]} burn blocks\")\n",
        "anchor_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69e34aa9",
      "metadata": {},
      "outputs": [],
      "source": [
        "cycles_df = hiro.list_pox_cycles(force_refresh=FORCE_REFRESH)\n",
        "print(f\"Retrieved {cycles_df.shape[0]} PoX cycles\")\n",
        "cycles_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d41f3b0",
      "metadata": {},
      "source": [
        "## 5. Tenure Panel Construction\n",
        "\n",
        "Join all datasets on `burn_block_height`, align prices to anchor timestamps, and derive reward value and \\(\r",
        "ho\\)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1349c29d",
      "metadata": {},
      "outputs": [],
      "source": [
        "if fees_df.empty or anchor_df.empty:\n",
        "    panel_df = pd.DataFrame()\n",
        "else:\n",
        "    panel_cfg = panel_builder.PanelConfig(coinbase_stx=COINBASE_STX)\n",
        "    panel_df = panel_builder.build_tenure_panel(\n",
        "        fees=fees_df,\n",
        "        rewards=rewards_df,\n",
        "        anchors=anchor_df,\n",
        "        prices=prices_df,\n",
        "        config=panel_cfg,\n",
        "    )\n",
        "    panel_df = panel_builder.merge_cycle_metadata(panel_df, cycles_df)\n",
        "    print(f\"Panel contains {panel_df.shape[0]} tenures\")\n",
        "panel_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "095aba55",
      "metadata": {},
      "source": [
        "## 6. Validation Checks\n",
        "\n",
        "Ensure we have consistent tenure coverage, expected coinbase value, and reasonable \\(\r",
        "ho\\) ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c1c59b",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not panel_df.empty:\n",
        "    missing_fees = panel_df['fees_stx_sum'].isna().sum()\n",
        "    coinbase_anomalies = panel_df['coinbase_flag'].sum()\n",
        "    rho_div_zero = panel_df['rho_flag_div0'].sum()\n",
        "    print(\"Missing fee entries:\", missing_fees)\n",
        "    print(\"Coinbase anomalies:\", coinbase_anomalies)\n",
        "    print(\"Zero reward value entries:\", rho_div_zero)\n",
        "\n",
        "    expected_burns = panel_df['burn_block_height'].iloc[-1] - panel_df['burn_block_height'].iloc[0] + 1\n",
        "    missing_burns = expected_burns - len(panel_df['burn_block_height'].unique())\n",
        "    print(\"Missing burn heights:\", missing_burns)\n",
        "\n",
        "    sample = panel_df.sample(min(20, len(panel_df)))\n",
        "    sample[['burn_block_height', 'fees_stx_sum', 'reward_amount_sats_sum', 'rho']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99f4a183",
      "metadata": {},
      "source": [
        "## 7. Fee Analytics Per Window\n",
        "\n",
        "Compute empirical fee-per-transaction statistics across rolling windows to benchmark against the 0.08 STX/tx baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8dee625",
      "metadata": {},
      "outputs": [],
      "source": [
        "fee_stats = {}\n",
        "for window in WINDOW_DAYS:\n",
        "    stats_df = fetch_fee_per_tx_summary(window, force_refresh=FORCE_REFRESH)\n",
        "    fee_stats[window] = stats_df\n",
        "    print(f\"Window {window}d -> observations: {stats_df.shape[0]}\")\n",
        "fee_summary_df = pd.concat({f\"{w}d\": df for w, df in fee_stats.items()}, names=[\"window\", \"row\"])\n",
        "fee_summary_df.groupby(level=\"window\").agg({\"avg_fee_stx\": \"mean\", \"median_fee_stx\": \"mean\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "495cc947",
      "metadata": {},
      "source": [
        "## 8. Scenario Engine\n",
        "\n",
        "Estimate the incremental transactions, BTC commits, and PoX APY shifts for fee uplifts. `stacked_supply_stx` defaults to a rolling estimate when available, otherwise falls back to 1.35B STX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd92e7c",
      "metadata": {},
      "outputs": [],
      "source": [
        "if panel_df.empty:\n",
        "    scenario_df = pd.DataFrame()\n",
        "else:\n",
        "    recent_panel = panel_df.tail(max(3_000, len(panel_df)))\n",
        "    mean_fee_stx = recent_panel['fees_stx_sum'].mean()\n",
        "    mean_stx_btc = recent_panel['stx_btc'].mean()\n",
        "    stacked_supply_estimate = (\n",
        "        recent_panel['reward_stx_total'].rolling(REWARD_BLOCKS_PER_CYCLE).sum().dropna().iloc[-1]\n",
        "        if len(recent_panel) >= REWARD_BLOCKS_PER_CYCLE\n",
        "        else 1_350_000_000.0\n",
        "    )\n",
        "    scenario_cfg = scenarios.ScenarioConfig(\n",
        "        fee_per_tx_stx=FEE_PER_TX_STX,\n",
        "        rho_candidates=RHO_RANGE,\n",
        "        coinbase_stx=COINBASE_STX,\n",
        "        reward_cycles_blocks=REWARD_BLOCKS_PER_CYCLE,\n",
        "        stacked_supply_stx=stacked_supply_estimate,\n",
        "    )\n",
        "    scenario_df = scenarios.build_scenarios(\n",
        "        uplift_rates=UPLIFT_POINTS,\n",
        "        mean_fee_stx=mean_fee_stx,\n",
        "        mean_stx_btc=mean_stx_btc,\n",
        "        config=scenario_cfg,\n",
        "    )\n",
        "    scenario_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9355c70",
      "metadata": {},
      "source": [
        "## 9. Visualizations\n",
        "\n",
        "Produce canonical charts: time series of fees and BTC commits, \\(\r",
        "ho\\) distribution, and scatter of reward value vs. BTC commits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c52c65",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not panel_df.empty:\n",
        "    time_fig = px.line(\n",
        "        panel_df.tail(5_000),\n",
        "        x=\"burn_block_time_iso\",\n",
        "        y=[\"fees_stx_sum\", \"reward_amount_sats_sum\"],\n",
        "        labels={\"value\": \"Amount\", \"burn_block_time_iso\": \"Burn Block Time\"},\n",
        "        title=\"Tenure Fees vs. BTC Commit (Rolling)\",\n",
        "    )\n",
        "    time_fig.show()\n",
        "\n",
        "    rho_fig = px.histogram(panel_df, x=\"rho\", nbins=50, title=\"Distribution of Rho\")\n",
        "    rho_fig.show()\n",
        "\n",
        "    scatter_fig = px.scatter(\n",
        "        panel_df,\n",
        "        x=\"reward_value_sats\",\n",
        "        y=\"reward_amount_sats_sum\",\n",
        "        trendline=\"ols\",\n",
        "        title=\"BTC Commit vs. Reward Value\",\n",
        "        labels={\"reward_value_sats\": \"Reward Value (sats)\", \"reward_amount_sats_sum\": \"BTC Commit (sats)\"},\n",
        "    )\n",
        "    scatter_fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de0e6118",
      "metadata": {},
      "source": [
        "## 10. Artifact Export\n",
        "\n",
        "Persist key datasets to `./data/` and `./out/` for downstream usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dba6ecb",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not panel_df.empty:\n",
        "    panel_path = OUT_PATH / \"tenure_panel.parquet\"\n",
        "    fees_path = OUT_PATH / \"fees_by_tenure.parquet\"\n",
        "    rewards_path = OUT_PATH / \"pox_rewards.parquet\"\n",
        "    price_path = OUT_PATH / \"prices.parquet\"\n",
        "    scenario_path = OUT_PATH / \"scenario_table.csv\"\n",
        "\n",
        "    panel_df.to_parquet(panel_path, index=False)\n",
        "    fees_df.to_parquet(fees_path, index=False)\n",
        "    rewards_df.to_parquet(rewards_path, index=False)\n",
        "    prices_df.to_parquet(price_path, index=False)\n",
        "    scenario_df.to_csv(scenario_path, index=False)\n",
        "\n",
        "    print(\"Saved panel ->\", panel_path)\n",
        "    print(\"Saved fees ->\", fees_path)\n",
        "    print(\"Saved rewards ->\", rewards_path)\n",
        "    print(\"Saved prices ->\", price_path)\n",
        "    print(\"Saved scenario table ->\", scenario_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "884740ae",
      "metadata": {},
      "source": [
        "## 11. Next Steps\n",
        "\n",
        "- Extend to cycle-level aggregates (sum commits, rewards, rho by PoX cycle).\n",
        "- Add pool attribution analytics by incorporating stacker addresses.\n",
        "- Compare realized fees with Hiro mempool fee estimates for additional validation.\n",
        "- Integrate notebook with Deepnote (recommended) for easy sharing; sync with this repo for reproducibility."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}